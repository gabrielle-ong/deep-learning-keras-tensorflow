{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### from keras import applications\n",
    "from keras import Sequential\n",
    "from keras.layers.core import Dense, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softmax',\n",
       " 'activity_regularizer': None,\n",
       " 'bias_constraint': None,\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'bias_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'distribution': 'uniform',\n",
       "   'mode': 'fan_avg',\n",
       "   'scale': 1.0,\n",
       "   'seed': None}},\n",
       " 'kernel_regularizer': None,\n",
       " 'name': 'predictions',\n",
       " 'trainable': True,\n",
       " 'units': 1000,\n",
       " 'use_bias': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1].get_config() # last layer - see units: this had 1000 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7f0178086f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.pop() # remove last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f017822f5c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f017822f898>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f017822f828>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f017825a748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0178202160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0178202e80>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f01781a34e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f01781b5358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f01781c5e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f01781d6278>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f0178176c50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0178198358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0178198e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f0178139358>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f01780dc400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f01780ed2b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f01780fdda0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f017810d208>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f01780afc18>,\n",
       " <keras.layers.core.Flatten at 0x7f01780cf358>,\n",
       " <keras.layers.core.Dense at 0x7f01780cfe80>,\n",
       " <keras.layers.core.Dense at 0x7f0178071898>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'activity_regularizer': None,\n",
       " 'bias_constraint': None,\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'bias_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'distribution': 'uniform',\n",
       "   'mode': 'fan_avg',\n",
       "   'scale': 1.0,\n",
       "   'seed': None}},\n",
       " 'kernel_regularizer': None,\n",
       " 'name': 'fc2',\n",
       " 'trainable': True,\n",
       " 'units': 4096,\n",
       " 'use_bias': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-1].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Dense(10,input_shape=(4096,)))\n",
    "top_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CREATE AN \"REAL\" MODEL FROM VGG16\n",
    "# BY COPYING ALL THE LAYERS OF VGG16\n",
    "new_model = Sequential()\n",
    "for l in model.layers:\n",
    "    new_model.add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONCATENATE THE TWO MODELS\n",
    "new_model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze top layers by setting .trainable = False (freeze the weights)\n",
    "for layer in new_model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias_constraint': None, 'activation': 'relu', 'name': 'fc2', 'kernel_regularizer': None, 'kernel_constraint': None, 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'mode': 'fan_avg', 'seed': None, 'distribution': 'uniform', 'scale': 1.0}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'units': 4096, 'bias_regularizer': None, 'activity_regularizer': None, 'trainable': False}\n",
      "\n",
      "[{'class_name': 'Dense', 'config': {'batch_input_shape': (None, 4096), 'bias_constraint': None, 'kernel_regularizer': None, 'name': 'dense_1', 'dtype': 'float32', 'activation': 'linear', 'kernel_constraint': None, 'use_bias': True, 'activity_regularizer': None, 'units': 10, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'mode': 'fan_avg', 'seed': None, 'distribution': 'uniform', 'scale': 1.0}}, 'trainable': True}}, {'class_name': 'Activation', 'config': {'activation': 'softmax', 'name': 'activation_1', 'trainable': True}}]\n"
     ]
    }
   ],
   "source": [
    "print (new_model.layers[-2].get_config())\n",
    "print()\n",
    "print (new_model.layers[-1].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "nb_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,3)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train,nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test,nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py:9: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "X_train_resized = np.zeros(shape = (1000,224,224,3))\n",
    "X_test_resized = np.zeros(shape = (100,224,224,3))\n",
    "\n",
    "for im_ind in range(1000):\n",
    "    X_train_resized[im_ind] = imresize(X_train[im_ind],(224,224))\n",
    "for im_ind in range(100):   \n",
    "    X_test_resized[im_ind] = imresize(X_test[im_ind],(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 930s 930ms/step - loss: 3.4224 - acc: 0.3400 - val_loss: 1.6244 - val_acc: 0.5600\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 937s 937ms/step - loss: 1.3746 - acc: 0.6070 - val_loss: 3.1973 - val_acc: 0.4100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01541a5cf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='sgd',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "new_model.fit(X_train_resized, Y_train[:1000], batch_size=32, \n",
    "          nb_epoch=10,verbose=1,\n",
    "          validation_data=(X_test_resized, Y_test[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 891s 891ms/step - loss: 1.1436 - acc: 0.6510 - val_loss: 1.6209 - val_acc: 0.5600\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 855s 855ms/step - loss: 0.8272 - acc: 0.7450 - val_loss: 3.2309 - val_acc: 0.4400\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 856s 856ms/step - loss: 0.7048 - acc: 0.7750 - val_loss: 1.5706 - val_acc: 0.6200\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 857s 857ms/step - loss: 0.6932 - acc: 0.7870 - val_loss: 1.0489 - val_acc: 0.6400\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 855s 855ms/step - loss: 0.3752 - acc: 0.8780 - val_loss: 0.8969 - val_acc: 0.6800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0177f96278>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train_resized, Y_train[:1000], batch_size=32, \n",
    "          nb_epoch=5,verbose=1,\n",
    "          validation_data=(X_test_resized, Y_test[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1018s 1s/step - loss: 0.3256 - acc: 0.9020 - val_loss: 1.0125 - val_acc: 0.6800\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 986s 986ms/step - loss: 0.2658 - acc: 0.9200 - val_loss: 0.9154 - val_acc: 0.7200\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 881s 881ms/step - loss: 0.2103 - acc: 0.9430 - val_loss: 1.5816 - val_acc: 0.5300\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 988s 988ms/step - loss: 0.1861 - acc: 0.9660 - val_loss: 0.9516 - val_acc: 0.6800\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 990s 990ms/step - loss: 0.1780 - acc: 0.9600 - val_loss: 0.9187 - val_acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0177f96048>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train_resized, Y_train[:1000], batch_size=32, \n",
    "          nb_epoch=5,verbose=1,\n",
    "          validation_data=(X_test_resized, Y_test[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
